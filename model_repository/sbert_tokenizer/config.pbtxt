name: 'sbert_tokenizer'
backend: 'python'
max_batch_size: 4
input: [
    {
        name: 'question',
        data_type: TYPE_STRING,
        dims: [-1]
    }
]
output [
    {
        name: 'sbert_input_ids',
        data_type: TYPE_INT64,
        dims: [-1]
    }
]
output [
    {
        name: 'sbert_attention_mask',
        data_type: TYPE_INT64,
        dims: [-1]
    }
]
output [
    {
        name: 'token_type_ids',
        data_type: TYPE_INT64,
        dims: [-1]
    }
]